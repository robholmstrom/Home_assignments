{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "input_dim = 784  # 28*28\n",
    "output_dim = nb_classes = 10\n",
    "batch_size = 128\n",
    "nb_epoch = 20\n",
    "\n",
    "X_train = X_train.reshape(60000, input_dim)\n",
    "X_test = X_test.reshape(10000, input_dim)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "Y_train = to_categorical(y_train, nb_classes)\n",
    "Y_test = to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you'll implement several ANN models with different batch sizes. Specifically\n",
    "\n",
    "Implement a three layer ANN model with 128, 64 and 10 neurons in the layers using 8 as the mini batch size.\n",
    "\n",
    "Implement a three layer ANN model with 128, 64 and 10 neurons in the layers using 128 as the mini batch size.\n",
    "\n",
    "Implement a three layer ANN model with 128, 64 and 10 neurons in the layers using the full sample as the batch.\n",
    "\n",
    "Compare the result of each model with each other. Which batch size did perform better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/robholmstrom/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.3632 - acc: 0.8974 - val_loss: 0.1875 - val_acc: 0.9434\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.1661 - acc: 0.9509 - val_loss: 0.1344 - val_acc: 0.9614\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1192 - acc: 0.9658 - val_loss: 0.1153 - val_acc: 0.9647\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0938 - acc: 0.9724 - val_loss: 0.0980 - val_acc: 0.9694\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.0765 - acc: 0.9773 - val_loss: 0.0941 - val_acc: 0.9695\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.0650 - acc: 0.9811 - val_loss: 0.0858 - val_acc: 0.9725\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.0562 - acc: 0.9841 - val_loss: 0.0790 - val_acc: 0.9746\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.0480 - acc: 0.9858 - val_loss: 0.0824 - val_acc: 0.9739\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.0420 - acc: 0.9873 - val_loss: 0.0793 - val_acc: 0.9740\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.0357 - acc: 0.9896 - val_loss: 0.0790 - val_acc: 0.9746\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.0318 - acc: 0.9909 - val_loss: 0.0780 - val_acc: 0.9766\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.0269 - acc: 0.9926 - val_loss: 0.0761 - val_acc: 0.9766\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.0235 - acc: 0.9936 - val_loss: 0.0774 - val_acc: 0.9754\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.0206 - acc: 0.9945 - val_loss: 0.0740 - val_acc: 0.9757\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.0176 - acc: 0.9958 - val_loss: 0.0809 - val_acc: 0.9756\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.0153 - acc: 0.9966 - val_loss: 0.0786 - val_acc: 0.9764\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 92us/sample - loss: 0.0134 - acc: 0.9972 - val_loss: 0.0766 - val_acc: 0.9768\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.0115 - acc: 0.9976 - val_loss: 0.0745 - val_acc: 0.9777\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.0100 - acc: 0.9982 - val_loss: 0.0784 - val_acc: 0.9765\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.0080 - acc: 0.9987 - val_loss: 0.0774 - val_acc: 0.9782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe4f087d850>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape = (784, ), activation = 'relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer= 'sgd', metrics = ['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size = 8, epochs = 20, validation_data = (X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.07737979623734136\n",
      "Test accuracy: 0.9782\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a three layer ANN model with 128, 64 and 10 neurons in the layers using sigmoid activation function for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.2934 - acc: 0.6819 - val_loss: 0.6123 - val_acc: 0.8593\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.5042 - acc: 0.8699 - val_loss: 0.4055 - val_acc: 0.8905\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 0.3915 - acc: 0.8920 - val_loss: 0.3471 - val_acc: 0.9021\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.3463 - acc: 0.9020 - val_loss: 0.3152 - val_acc: 0.9105\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.3193 - acc: 0.9094 - val_loss: 0.2925 - val_acc: 0.9173\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.2997 - acc: 0.9140 - val_loss: 0.2796 - val_acc: 0.9206\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.2843 - acc: 0.9187 - val_loss: 0.2670 - val_acc: 0.9243\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.2713 - acc: 0.9224 - val_loss: 0.2558 - val_acc: 0.9271\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.2597 - acc: 0.9256 - val_loss: 0.2471 - val_acc: 0.9297\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.2498 - acc: 0.9287 - val_loss: 0.2377 - val_acc: 0.9323\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 0.2403 - acc: 0.9318 - val_loss: 0.2299 - val_acc: 0.9351\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.2318 - acc: 0.9338 - val_loss: 0.2228 - val_acc: 0.9365\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.2239 - acc: 0.9362 - val_loss: 0.2165 - val_acc: 0.9388\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.2165 - acc: 0.9389 - val_loss: 0.2093 - val_acc: 0.9406\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.2094 - acc: 0.9406 - val_loss: 0.2045 - val_acc: 0.9417\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.2028 - acc: 0.9430 - val_loss: 0.1993 - val_acc: 0.9423\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.1969 - acc: 0.9452 - val_loss: 0.1943 - val_acc: 0.9443\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.1911 - acc: 0.9462 - val_loss: 0.1895 - val_acc: 0.9454\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.1856 - acc: 0.9475 - val_loss: 0.1860 - val_acc: 0.9463\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.1807 - acc: 0.9495 - val_loss: 0.1806 - val_acc: 0.9473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe5208d1e10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape = (784, ), activation = 'relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer= 'sgd', metrics = ['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size = 128, epochs = 20, validation_data = (X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.18060938156470657\n",
      "Test accuracy: 0.9473\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a three layer ANN model with 128, 64 and 10 neurons in the layers using ReLU activation function for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 2.3149 - acc: 0.1090 - val_loss: 2.2947 - val_acc: 0.1193\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 0s 3us/sample - loss: 2.2846 - acc: 0.1255 - val_loss: 2.2655 - val_acc: 0.1420\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 0s 3us/sample - loss: 2.2569 - acc: 0.1478 - val_loss: 2.2385 - val_acc: 0.1666\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 0s 3us/sample - loss: 2.2309 - acc: 0.1755 - val_loss: 2.2127 - val_acc: 0.1982\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 0s 3us/sample - loss: 2.2060 - acc: 0.2053 - val_loss: 2.1876 - val_acc: 0.2312\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 0s 3us/sample - loss: 2.1813 - acc: 0.2407 - val_loss: 2.1625 - val_acc: 0.2695\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 0s 3us/sample - loss: 2.1566 - acc: 0.2764 - val_loss: 2.1372 - val_acc: 0.3053\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 0s 3us/sample - loss: 2.1314 - acc: 0.3112 - val_loss: 2.1113 - val_acc: 0.3396\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 0s 3us/sample - loss: 2.1056 - acc: 0.3458 - val_loss: 2.0847 - val_acc: 0.3721\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 0s 3us/sample - loss: 2.0789 - acc: 0.3792 - val_loss: 2.0571 - val_acc: 0.4028\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 0s 3us/sample - loss: 2.0513 - acc: 0.4100 - val_loss: 2.0288 - val_acc: 0.4362\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 0s 3us/sample - loss: 2.0230 - acc: 0.4396 - val_loss: 1.9996 - val_acc: 0.4619\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 0s 3us/sample - loss: 1.9938 - acc: 0.4666 - val_loss: 1.9697 - val_acc: 0.4854\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 0s 3us/sample - loss: 1.9639 - acc: 0.4913 - val_loss: 1.9391 - val_acc: 0.5115\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 0s 3us/sample - loss: 1.9333 - acc: 0.5148 - val_loss: 1.9077 - val_acc: 0.5346\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 0s 3us/sample - loss: 1.9019 - acc: 0.5372 - val_loss: 1.8757 - val_acc: 0.5576\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 0s 3us/sample - loss: 1.8700 - acc: 0.5576 - val_loss: 1.8431 - val_acc: 0.5749\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 0s 3us/sample - loss: 1.8374 - acc: 0.5758 - val_loss: 1.8099 - val_acc: 0.5934\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 0s 4us/sample - loss: 1.8043 - acc: 0.5941 - val_loss: 1.7761 - val_acc: 0.6094\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 0s 3us/sample - loss: 1.7707 - acc: 0.6109 - val_loss: 1.7418 - val_acc: 0.6268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe5309e0dd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape = (784, ), activation = 'relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer= 'sgd', metrics = ['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size = 10000, epochs = 20, validation_data = (X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 1.741822917175293\n",
      "Test accuracy: 0.6268\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smallest batch size works slowest but with best accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you'll implement several ANN models with different learning rates for the stochastic gradient descent. In all of the models below, use 128 as your mini batch size.\n",
    "\n",
    "Implement a three layer ANN model with 128, 64 and 10 neurons in the layers using 0.01 as the learning rate.\n",
    "\n",
    "Implement a three layer ANN model with 128, 64 and 10 neurons in the layers using 100 as the learning rate.\n",
    "\n",
    "Implement a three layer ANN model with 128, 64 and 10 neurons in the layers using 0.0000001 as the learning rate.\n",
    "\n",
    "Compare the result of each model with each other. Which learning rate did perform better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "WARNING:tensorflow:From /Users/robholmstrom/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 1.0168 - acc: 0.2546 - val_loss: 1.0049 - val_acc: 0.4006\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.9953 - acc: 0.5125 - val_loss: 0.9823 - val_acc: 0.5922\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9544 - acc: 0.6124 - val_loss: 0.9142 - val_acc: 0.6497\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8414 - acc: 0.6658 - val_loss: 0.7346 - val_acc: 0.7118\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.6334 - acc: 0.7580 - val_loss: 0.5268 - val_acc: 0.8246\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.4663 - acc: 0.8445 - val_loss: 0.3893 - val_acc: 0.8748\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.3618 - acc: 0.8753 - val_loss: 0.3127 - val_acc: 0.8871\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.3042 - acc: 0.8873 - val_loss: 0.2725 - val_acc: 0.8963\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.2710 - acc: 0.8938 - val_loss: 0.2477 - val_acc: 0.9014\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.2495 - acc: 0.8997 - val_loss: 0.2307 - val_acc: 0.9065\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.2337 - acc: 0.9035 - val_loss: 0.2186 - val_acc: 0.9095\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.2219 - acc: 0.9062 - val_loss: 0.2085 - val_acc: 0.9127\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2122 - acc: 0.9100 - val_loss: 0.2015 - val_acc: 0.9144\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2042 - acc: 0.9123 - val_loss: 0.1937 - val_acc: 0.9173\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1972 - acc: 0.9155 - val_loss: 0.1886 - val_acc: 0.9185\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1914 - acc: 0.9170 - val_loss: 0.1847 - val_acc: 0.9201\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1859 - acc: 0.9194 - val_loss: 0.1787 - val_acc: 0.9222\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1813 - acc: 0.9208 - val_loss: 0.1754 - val_acc: 0.9228\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1769 - acc: 0.9225 - val_loss: 0.1714 - val_acc: 0.9243\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1729 - acc: 0.9239 - val_loss: 0.1683 - val_acc: 0.9265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe4e855c710>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape = (784, ), activation = 'relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "sgd = SGD(lr= 0.01)\n",
    "model.compile(loss = 'categorical_hinge', optimizer= sgd, metrics = ['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size = 128, epochs = 20, validation_data = (X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.16829807743430136\n",
      "Test accuracy: 0.9265\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 1.8039 - acc: 0.0971 - val_loss: 1.8036 - val_acc: 0.0982\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 1.8053 - acc: 0.0974 - val_loss: 1.8036 - val_acc: 0.0982\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.8053 - acc: 0.0974 - val_loss: 1.8036 - val_acc: 0.0982\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 1.8053 - acc: 0.0974 - val_loss: 1.8036 - val_acc: 0.0982\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 1.8053 - acc: 0.0974 - val_loss: 1.8036 - val_acc: 0.0982\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 1.8053 - acc: 0.0974 - val_loss: 1.8036 - val_acc: 0.0982\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 1.8053 - acc: 0.0974 - val_loss: 1.8036 - val_acc: 0.0982\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 1.8053 - acc: 0.0974 - val_loss: 1.8036 - val_acc: 0.0982\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.8053 - acc: 0.0974 - val_loss: 1.8036 - val_acc: 0.0982\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.8053 - acc: 0.0974 - val_loss: 1.8036 - val_acc: 0.0982\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.8053 - acc: 0.0974 - val_loss: 1.8036 - val_acc: 0.0982\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.8053 - acc: 0.0974 - val_loss: 1.8036 - val_acc: 0.0982\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.8053 - acc: 0.0974 - val_loss: 1.8036 - val_acc: 0.0982\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.8053 - acc: 0.0974 - val_loss: 1.8036 - val_acc: 0.0982\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.8053 - acc: 0.0974 - val_loss: 1.8036 - val_acc: 0.0982\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.8053 - acc: 0.0974 - val_loss: 1.8036 - val_acc: 0.0982\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.8053 - acc: 0.0974 - val_loss: 1.8036 - val_acc: 0.0982\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.8053 - acc: 0.0974 - val_loss: 1.8036 - val_acc: 0.0982\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.8053 - acc: 0.0974 - val_loss: 1.8036 - val_acc: 0.0982\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.8053 - acc: 0.0974 - val_loss: 1.8036 - val_acc: 0.0982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe4e8924e50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape = (784, ), activation = 'relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "sgd = SGD(lr= 100)\n",
    "model.compile(loss = 'categorical_hinge', optimizer= sgd, metrics = ['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size = 128, epochs = 20, validation_data = (X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 1.8036\n",
      "Test accuracy: 0.0982\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 1.0692 - acc: 0.0477 - val_loss: 1.0693 - val_acc: 0.0449\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.0692 - acc: 0.0477 - val_loss: 1.0692 - val_acc: 0.0449\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.0692 - acc: 0.0477 - val_loss: 1.0692 - val_acc: 0.0449\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.0692 - acc: 0.0477 - val_loss: 1.0692 - val_acc: 0.0449\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.0692 - acc: 0.0477 - val_loss: 1.0692 - val_acc: 0.0449\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.0692 - acc: 0.0477 - val_loss: 1.0692 - val_acc: 0.0449\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.0692 - acc: 0.0477 - val_loss: 1.0692 - val_acc: 0.0449\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.0692 - acc: 0.0477 - val_loss: 1.0692 - val_acc: 0.0449\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.0692 - acc: 0.0477 - val_loss: 1.0692 - val_acc: 0.0449\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.0692 - acc: 0.0477 - val_loss: 1.0692 - val_acc: 0.0448\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.0692 - acc: 0.0477 - val_loss: 1.0692 - val_acc: 0.0448\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.0692 - acc: 0.0477 - val_loss: 1.0692 - val_acc: 0.0448\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 1.0692 - acc: 0.0477 - val_loss: 1.0692 - val_acc: 0.0448\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.0692 - acc: 0.0477 - val_loss: 1.0692 - val_acc: 0.0448\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.0692 - acc: 0.0477 - val_loss: 1.0692 - val_acc: 0.0448\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.0692 - acc: 0.0477 - val_loss: 1.0692 - val_acc: 0.0448\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.0692 - acc: 0.0477 - val_loss: 1.0692 - val_acc: 0.0447\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 1.0692 - acc: 0.0477 - val_loss: 1.0692 - val_acc: 0.0447\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 1.0692 - acc: 0.0477 - val_loss: 1.0692 - val_acc: 0.0447\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 1.0692 - acc: 0.0477 - val_loss: 1.0692 - val_acc: 0.0447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe4f0e67050>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape = (784, ), activation = 'relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "sgd = SGD(lr= 0.0000001)\n",
    "model.compile(loss = 'categorical_hinge', optimizer= sgd, metrics = ['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size = 128, epochs = 20, validation_data = (X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 1.0692047861099243\n",
      "Test accuracy: 0.0447\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both super high and super low learning rates produced near 0 \n",
    "#accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
