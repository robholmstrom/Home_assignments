{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split your data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess your data so that you can feed it into ANN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 784  # 28*28\n",
    "output_dim = nb_classes = 10\n",
    "batch_size = 128\n",
    "nb_epoch = 20\n",
    "\n",
    "X_train = X_train.reshape(60000, input_dim)\n",
    "X_test = X_test.reshape(10000, input_dim)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "Y_train = to_categorical(y_train, nb_classes)\n",
    "Y_test = to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try different ANN models and train them on your training set. You can play with: \n",
    "\n",
    "## 3.1. Number of layers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.4009563367128372\n",
      "Test accuracy: 0.857\n",
      "Train accuracy: 0.86985\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape = (784, ), activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer= 'sgd', metrics = ['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size = 128, epochs = 20, verbose = 0)\n",
    "\n",
    "score_test = model.evaluate(X_test, Y_test, verbose=0)\n",
    "score_train = model.evaluate(X_train, Y_train, verbose=0)\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score_test[1])\n",
    "print('Train accuracy:',score_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.4009563367128372\n",
      "Test accuracy: 0.8572\n",
      "Train accuracy: 0.8734\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape = (784, ), activation = 'relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer= 'sgd', metrics = ['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size = 128, epochs = 20, verbose = 0)\n",
    "\n",
    "score_test = model.evaluate(X_test, Y_test, verbose=0)\n",
    "score_train = model.evaluate(X_train, Y_train, verbose=0)\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score_test[1])\n",
    "print('Train accuracy:',score_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.4009563367128372\n",
      "Test accuracy: 0.8542\n",
      "Train accuracy: 0.87035\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape = (784, ), activation = 'relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer= 'sgd', metrics = ['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size = 128, epochs = 20, verbose = 0)\n",
    "\n",
    "score_test = model.evaluate(X_test, Y_test, verbose=0)\n",
    "score_train = model.evaluate(X_train, Y_train, verbose=0)\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score_test[1])\n",
    "print('Train accuracy:',score_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Activation functions of the layers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.4009563367128372\n",
      "Test accuracy: 0.8558\n",
      "Train accuracy: 0.8735\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape = (784, ), activation = 'relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer= 'sgd', metrics = ['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size = 128, epochs = 20, verbose = 0)\n",
    "\n",
    "score_test = model.evaluate(X_test, Y_test, verbose=0)\n",
    "score_train = model.evaluate(X_train, Y_train, verbose=0)\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score_test[1])\n",
    "print('Train accuracy:',score_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.4009563367128372\n",
      "Test accuracy: 0.8569\n",
      "Train accuracy: 0.87405\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape = (784, ), activation = 'tanh'))\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer= 'sgd', metrics = ['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size = 128, epochs = 20, verbose = 0)\n",
    "\n",
    "score_test = model.evaluate(X_test, Y_test, verbose=0)\n",
    "score_train = model.evaluate(X_train, Y_train, verbose=0)\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score_test[1])\n",
    "print('Train accuracy:',score_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.4009563367128372\n",
      "Test accuracy: 0.5996\n",
      "Train accuracy: 0.60261667\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape = (784, ), activation = 'sigmoid'))\n",
    "model.add(Dense(64, activation='sigmoid'))\n",
    "model.add(Dense(64, activation='sigmoid'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer= 'sgd', metrics = ['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size = 128, epochs = 20, verbose = 0)\n",
    "\n",
    "score_test = model.evaluate(X_test, Y_test, verbose=0)\n",
    "score_train = model.evaluate(X_train, Y_train, verbose=0)\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score_test[1])\n",
    "print('Train accuracy:',score_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Number of neurons in the layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.4009563367128372\n",
      "Test accuracy: 0.8615\n",
      "Train accuracy: 0.88068336\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1028, input_shape = (784, ), activation = 'tanh'))\n",
    "model.add(Dense(128, activation='tanh'))\n",
    "model.add(Dense(128, activation = 'tanh'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer= 'sgd', metrics = ['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size = 128, epochs = 20, verbose = 0)\n",
    "\n",
    "score_test = model.evaluate(X_test, Y_test, verbose=0)\n",
    "score_train = model.evaluate(X_train, Y_train, verbose=0)\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score_test[1])\n",
    "print('Train accuracy:',score_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.4009563367128372\n",
      "Test accuracy: 0.8616\n",
      "Train accuracy: 0.88086665\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1028, input_shape = (784, ), activation = 'tanh'))\n",
    "model.add(Dense(128, activation='tanh'))\n",
    "model.add(Dense(64, activation = 'tanh'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer= 'sgd', metrics = ['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size = 128, epochs = 20, verbose = 0)\n",
    "\n",
    "score_test = model.evaluate(X_test, Y_test, verbose=0)\n",
    "score_train = model.evaluate(X_train, Y_train, verbose=0)\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score_test[1])\n",
    "print('Train accuracy:',score_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.4009563367128372\n",
      "Test accuracy: 0.8538\n",
      "Train accuracy: 0.87196666\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape = (784, ), activation = 'tanh'))\n",
    "model.add(Dense(128, activation='tanh'))\n",
    "model.add(Dense(64, activation = 'tanh'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer= 'sgd', metrics = ['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size = 128, epochs = 20, verbose = 0)\n",
    "\n",
    "score_test = model.evaluate(X_test, Y_test, verbose=0)\n",
    "score_train = model.evaluate(X_train, Y_train, verbose=0)\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score_test[1])\n",
    "print('Train accuracy:',score_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Different batch sizes during training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.4009563367128372\n",
      "Test accuracy: 0.881\n",
      "Train accuracy: 0.92831665\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1028, input_shape = (784, ), activation = 'tanh'))\n",
    "model.add(Dense(128, activation='tanh'))\n",
    "model.add(Dense(64, activation = 'tanh'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer= 'sgd', metrics = ['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size = 10, epochs = 20, verbose = 0)\n",
    "\n",
    "score_test = model.evaluate(X_test, Y_test, verbose=0)\n",
    "score_train = model.evaluate(X_train, Y_train, verbose=0)\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score_test[1])\n",
    "print('Train accuracy:',score_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.4009563367128372\n",
      "Test accuracy: 0.8613\n",
      "Train accuracy: 0.88313335\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1028, input_shape = (784, ), activation = 'tanh'))\n",
    "model.add(Dense(128, activation='tanh'))\n",
    "model.add(Dense(64, activation = 'tanh'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer= 'sgd', metrics = ['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size = 100, epochs = 20, verbose = 0)\n",
    "\n",
    "score_test = model.evaluate(X_test, Y_test, verbose=0)\n",
    "score_train = model.evaluate(X_train, Y_train, verbose=0)\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score_test[1])\n",
    "print('Train accuracy:',score_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.4009563367128372\n",
      "Test accuracy: 0.8194\n",
      "Train accuracy: 0.8329667\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1028, input_shape = (784, ), activation = 'tanh'))\n",
    "model.add(Dense(128, activation='tanh'))\n",
    "model.add(Dense(64, activation = 'tanh'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer= 'sgd', metrics = ['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size = 1000, epochs = 20, verbose = 0)\n",
    "\n",
    "score_test = model.evaluate(X_test, Y_test, verbose=0)\n",
    "score_train = model.evaluate(X_train, Y_train, verbose=0)\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score_test[1])\n",
    "print('Train accuracy:',score_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare your models' training scores and interpret your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For layer number with the relu \n",
    "For activation function, sigmoid preformed noticably worse while relu and tanh were about the same\n",
    "For neuron number with tanh was relatively similar from \n",
    "For batch number, higher numbers performed worse in accuracy, although they were much faster than lowest batch size tested.\n",
    "\n",
    "As an interpretation of the results from the training data, the sigmoid function should not be used as activation functions in hidden layers for multiclass classifications. Further, while low batch size was best in accuracy, this took a long time to compute (without a GPU)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate your models' performances on your test set. Compare the results of your models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While decreasing batch size showed best improvement in training and test performance, the consistency lowest between training and test by about 4 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
